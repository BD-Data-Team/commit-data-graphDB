{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing library and creating spark-session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyGithub\n",
      "  Downloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pynacl>=1.4.0\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m820.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /opt/conda/lib/python3.7/site-packages (from PyGithub) (2.28.1)\n",
      "Requirement already satisfied: pyjwt[crypto]>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from PyGithub) (2.5.0)\n",
      "Collecting deprecated\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting types-cryptography>=3.3.21\n",
      "  Downloading types_cryptography-3.3.23.2-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: cryptography>=3.3.1 in /opt/conda/lib/python3.7/site-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (38.0.1)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from pynacl>=1.4.0->PyGithub) (1.15.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.14.0->PyGithub) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.14.0->PyGithub) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.14.0->PyGithub) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.14.0->PyGithub) (3.4)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.15.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.21)\n",
      "Installing collected packages: types-cryptography, wrapt, pynacl, deprecated, PyGithub\n",
      "Successfully installed PyGithub-1.59.1 deprecated-1.2.14 pynacl-1.5.0 types-cryptography-3.3.23.2 wrapt-1.15.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "fileDir = \"/home/jovyan/notebooks/\"\n",
    "sys.path.append(fileDir)\n",
    "\n",
    "from utilities import *\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added dependencies: \n",
      " ['neo4j-connector-apache-spark_2.12-5.0.1_for_spark_3.jar']\n"
     ]
    }
   ],
   "source": [
    "session = create_spark_session(\"Neo4j GitHub\", SparkConnector.NEO4J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDFS_URL = \"hdfs://namenode:9000//data-team\"\n",
    "PREFIX = \"sample_\" # \"sample_\" or \"\"\n",
    "SUFFIX = \"_100\" # \"_10\" or \"_100\" or \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Dataframe saved to NEO4J\n",
      "Load time: 0.34276530345280964 min\n",
      "Preprocessing time: 0.003538235028584798 min\n",
      "Writing time: 3.3934589425722756 min\n"
     ]
    }
   ],
   "source": [
    "load_start_time = time.time()\n",
    "repositories_json = session.read.json(f\"{HDFS_URL}/{PREFIX}repositories{SUFFIX}.json\") \\\n",
    "    .withColumnRenamed(\"repo_name\", \"repo\") \\\n",
    "\n",
    "repositories_csv = session.read.csv(f\"{HDFS_URL}/repo_API_data.csv\", header=True, inferSchema=True)\n",
    "repositories_csv = repositories_csv.select(\"repo_name\",\"stargazers_count\",\"topics\")\n",
    "\n",
    "repositories = repositories_json.join(repositories_csv, repositories_json.repo == repositories_csv.repo_name, \"left\") \\\n",
    "    .select(repositories_json[\"repo\"].alias(\"repo_name\"), \n",
    "            repositories_json[\"watch_count\"], repositories_csv[\"stargazers_count\"], \n",
    "            repositories_csv[\"topics\"])\n",
    "\n",
    "languages = session.read.json(f\"{HDFS_URL}/{PREFIX}languages{SUFFIX}.json\")\n",
    "\n",
    "licences = session.read.json(f\"{HDFS_URL}/{PREFIX}licences{SUFFIX}.json\")\n",
    "\n",
    "commits = session.read.json(f\"{HDFS_URL}/{PREFIX}commits{SUFFIX}.json\") # cambia se ti serve il dataset completo\n",
    "\n",
    "load_end_time = time.time()\n",
    "\n",
    "load_time = (load_end_time - load_start_time)\n",
    "\n",
    "preprc_start_time = time.time()\n",
    "git_commits = commits \\\n",
    "    .select(\"commit\", \"subject\", \"message\", \"committer.date.seconds\", \"author.date.seconds\")\n",
    "\n",
    "newColumns = [\"id\",\"title\",\"message\",\"committer_date\",\"author_date\"]\n",
    "git_commits = git_commits \\\n",
    "    .toDF(*newColumns)\n",
    "\n",
    "git_repositories = repositories \\\n",
    "    .withColumnRenamed(\"repo_name\", \"name\")\n",
    "\n",
    "git_languages = languages.withColumn(\"name\", F.explode(languages[\"language.name\"])) \\\n",
    "    .dropDuplicates([\"name\"]) \\\n",
    "    .select(\"name\")\n",
    "\n",
    "git_licenses = licences.select(\"license\") \\\n",
    "    .withColumnRenamed(\"license\",\"name\") \\\n",
    "    .dropDuplicates([\"name\"])\n",
    "\n",
    "git_contributor = commits.select(\"author.*\") \\\n",
    "    .union(commits.select(\"committer.*\")) \\\n",
    "    .dropDuplicates([\"email\"]) \\\n",
    "    .select(\"name\",\"email\")\n",
    "\n",
    "belongs_to = commits.select(\"commit\",\"repo\")\n",
    "contains = commits.select(\"repo\",\"commit\")\n",
    "\n",
    "parent = commits.select(\"commit\", \"parent\") \\\n",
    "    .withColumn(\"parent\", F.explode(commits[\"parent\"])) \\\n",
    "    .dropDuplicates([\"commit\",\"parent\"])\n",
    "\n",
    "has = licences.select(\"repo_name\", \"license\") \\\n",
    "    .dropDuplicates([\"repo_name\", \"license\"])\n",
    "\n",
    "author = commits.select(\"author.email\", \"commit\", \"author.date.seconds\") \\\n",
    "    .withColumnRenamed(\"seconds\",\"ts\")\n",
    "author = author \\\n",
    "    .filter(author[\"email\"] != \"\") \\\n",
    "    .withColumn(\"ts\", author[\"ts\"].cast(T.IntegerType())) \\\n",
    "    .dropDuplicates([\"email\",\"commit\"])\n",
    "\n",
    "committed = commits.select(\"committer.email\", \"commit\", \"committer.date.seconds\") \\\n",
    "    .withColumnRenamed(\"seconds\",\"ts\") \n",
    "committed = committed \\\n",
    "    .filter(committed[\"email\"] != \"\") \\\n",
    "    .withColumn(\"ts\", committed[\"ts\"].cast(T.IntegerType())) \\\n",
    "    .dropDuplicates([\"email\",\"commit\"])\n",
    "\n",
    "writted_in = languages.withColumn(\"lang\", F.explode(languages[\"language\"]))\n",
    "writted_in = writted_in \\\n",
    "    .withColumn(\"language\", writted_in[\"lang.name\"]) \\\n",
    "    .withColumn(\"bytes\", writted_in[\"lang.bytes\"].cast(T.IntegerType())) \\\n",
    "    .select(\"repo_name\", \"language\", \"bytes\")\n",
    "\n",
    "preproc_end_time = time.time()\n",
    "preproc_time = (preproc_end_time - preprc_start_time)\n",
    "\n",
    "writing_start_time = time.time()\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"node.keys\"] = \"name\"\n",
    "options[\"labels\"] = \":GitRepository\"\n",
    "options[\"schema.optimization.type\"] = \"INDEX\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, git_repositories, \"Overwrite\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"node.keys\"] = \"email\"\n",
    "options[\"labels\"] = \":GitContributor\"\n",
    "options[\"schema.optimization.type\"] = \"INDEX\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, git_contributor, \"Overwrite\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"node.keys\"] = \"name\"\n",
    "options[\"labels\"] = \":GitLanguage\"\n",
    "options[\"schema.optimization.type\"] = \"INDEX\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, git_languages, \"Overwrite\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"node.keys\"] = \"name\"\n",
    "options[\"labels\"] = \":GitLicense\"\n",
    "options[\"schema.optimization.type\"] = \"INDEX\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, git_licenses, \"Overwrite\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"node.keys\"] = \"id\"\n",
    "options[\"labels\"] = \":GitCommit\"\n",
    "options[\"schema.optimization.type\"] = \"INDEX\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, git_commits, \"Overwrite\", options=options)\n",
    "\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"relationship\"] = \"BELONGS_TO\"\n",
    "options[\"relationship.save.strategy\"] = \"keys\"\n",
    "\n",
    "\n",
    "options[\"relationship.source.labels\"] = \"GitCommit\"\n",
    "options[\"relationship.source.node.keys\"] = \"commit:id\"\n",
    "options[\"relationship.source.save.mode\"] = \"Match\"\n",
    "\n",
    "options[\"relationship.target.labels\"] = \"GitRepository\"\n",
    "options[\"relationship.target.node.keys\"] = \"repo:name\"\n",
    "options[\"relationship.target.save.mode\"] = \"Match\"\n",
    "\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, belongs_to, \"Append\", options=options)\n",
    "\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"relationship\"] = \"CONTAINS\"\n",
    "options[\"relationship.save.strategy\"] = \"keys\"\n",
    "\n",
    "options[\"relationship.source.labels\"] = \"GitrRepository\"\n",
    "options[\"relationship.source.node.keys\"] = \"repo:name\"\n",
    "options[\"relationship.source.save.mode\"] = \"Match\"\n",
    "\n",
    "options[\"relationship.target.labels\"] = \"GitCommit\"\n",
    "options[\"relationship.target.node.keys\"] = \"commit:id\"\n",
    "options[\"relationship.target.save.mode\"] = \"Match\"\n",
    "\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, contains, \"Append\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"relationship\"] = \"PARENT\"\n",
    "options[\"relationship.save.strategy\"] = \"keys\"\n",
    "\n",
    "options[\"relationship.source.labels\"] = \"GitCommit\"\n",
    "options[\"relationship.source.node.keys\"] = \"commit:id\"\n",
    "options[\"relationship.source.save.mode\"] = \"Match\"\n",
    "\n",
    "options[\"relationship.target.labels\"] = \"GitCommit\"\n",
    "options[\"relationship.target.node.keys\"] = \"parent:id\"\n",
    "options[\"relationship.target.save.mode\"] = \"Match\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, parent, \"Append\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"relationship\"] = \"HAS\"\n",
    "options[\"relationship.save.strategy\"] = \"keys\"\n",
    "\n",
    "options[\"relationship.source.labels\"] = \"GitRepository\"\n",
    "options[\"relationship.source.node.keys\"] = \"repo_name:name\"\n",
    "options[\"relationship.source.save.mode\"] = \"Match\"\n",
    "\n",
    "options[\"relationship.target.labels\"] = \"GitLicense\"\n",
    "options[\"relationship.target.node.keys\"] = \"license:name\"\n",
    "options[\"relationship.target.save.mode\"] = \"Match\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, has, \"Append\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"relationship\"] = \"AUTHOR\"\n",
    "options[\"relationship.save.strategy\"] = \"keys\"\n",
    "options[\"relationship.properties\"] = \"ts\"\n",
    "\n",
    "options[\"relationship.source.labels\"] = \"GitContributor\"\n",
    "options[\"relationship.source.node.keys\"] = \"email:email\"\n",
    "options[\"relationship.source.save.mode\"] = \"Match\"\n",
    "\n",
    "options[\"relationship.target.labels\"] = \"GitCommit\"\n",
    "options[\"relationship.target.node.keys\"] = \"commit:id\"\n",
    "options[\"relationship.target.save.mode\"] = \"Match\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, author, \"Append\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"relationship\"] = \"COMMITTED\"\n",
    "options[\"relationship.save.strategy\"] = \"keys\"\n",
    "options[\"relationship.properties\"] = \"ts\"\n",
    "\n",
    "options[\"relationship.source.labels\"] = \"GitContributor\"\n",
    "options[\"relationship.source.node.keys\"] = \"email:email\"\n",
    "options[\"relationship.source.save.mode\"] = \"Match\"\n",
    "\n",
    "options[\"relationship.target.labels\"] = \"GitCommit\"\n",
    "options[\"relationship.target.node.keys\"] = \"commit:id\"\n",
    "options[\"relationship.target.save.mode\"] = \"Match\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, committed, \"Append\", options=options)\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "\n",
    "options[\"relationship\"] = \"WRITTED_IN\"\n",
    "options[\"relationship.save.strategy\"] = \"keys\"\n",
    "options[\"relationship.properties\"] = \"bytes\"\n",
    "\n",
    "options[\"relationship.source.labels\"] = \"GitRepository\"\n",
    "options[\"relationship.source.node.keys\"] = \"repo_name:name\"\n",
    "options[\"relationship.source.save.mode\"] = \"Match\"\n",
    "\n",
    "options[\"relationship.target.labels\"] = \"GitLanguage\"\n",
    "options[\"relationship.target.node.keys\"] = \"language:name\"\n",
    "options[\"relationship.target.save.mode\"] = \"Match\"\n",
    "\n",
    "spark_write(SparkConnector.NEO4J, writted_in, \"Append\", options=options)\n",
    "writing_end_time = time.time()\n",
    "writing_time = (writing_end_time - writing_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load time: 20.56591820716858 sec\n",
      "Preprocessing time: 0.2122941017150879 sec\n",
      "Writing time: 203.60753655433655 sec\n"
     ]
    }
   ],
   "source": [
    "print(f\"Load time: {load_time} sec\")\n",
    "print(f\"Preprocessing time: {preproc_time} sec\")\n",
    "print(f\"Writing time: {writing_time} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded from neo4j\n",
      "Scenario 1: 1.9277441501617432 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(contrib=Row(<id>=678, <labels>=['GitContributor'], name='dependabot[bot]', email='1c358da00a777d4e9898c1280ab801e2df165188@users.noreply.github.com'), repo_count=25),\n",
       " Row(contrib=Row(<id>=10014, <labels>=['GitContributor'], name='Ikko Ashimine', email='d41f8067726d843438db002d5555099b4901d7c1@gmail.com'), repo_count=16),\n",
       " Row(contrib=Row(<id>=21466, <labels>=['GitContributor'], name='Prayag Verma', email='35a46e17bc00e93336a001ea5a30f33595fd0d03@gmail.com'), repo_count=16),\n",
       " Row(contrib=Row(<id>=33615, <labels>=['GitContributor'], name='Josh Soref', email='dc510c92cc1794ea84000fde88becdce67bf7624@users.noreply.github.com'), repo_count=13),\n",
       " Row(contrib=Row(<id>=25567, <labels>=['GitContributor'], name='ReadmeCritic', email='76d2ec468599ff7a19f706781bc84ca0c636b360@gmail.com'), repo_count=12),\n",
       " Row(contrib=Row(<id>=1386, <labels>=['GitContributor'], name='jamesgeorge007', email='3e5d4505bd1e679d62cbd9e85b63ce0b6e249349@gmail.com'), repo_count=9),\n",
       " Row(contrib=Row(<id>=34726, <labels>=['GitContributor'], name='Christian Oliff', email='ea3d259ffd1207ecbeda2bb424a3bb2239b05950@yahoo.com'), repo_count=9),\n",
       " Row(contrib=Row(<id>=7311, <labels>=['GitContributor'], name='dependabot-preview[bot]', email='6a4c1c4838f800d1998274cd5234e1f65c55e90c@users.noreply.github.com'), repo_count=9),\n",
       " Row(contrib=Row(<id>=14856, <labels>=['GitContributor'], name='PatrickJS', email='64b2b6d12bfe4baae7dad3d018f8cbf6b0e7a044@gdi2290.com'), repo_count=8),\n",
       " Row(contrib=Row(<id>=37738, <labels>=['GitContributor'], name='Pascal Borreli', email='de9b8d32d21ac4abee992cab0591365746b5103f@borreli.com'), repo_count=8)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scenario 1\n",
    "start_time = time.time()\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "options[\"query\"] =  \"\"\"\n",
    "                        MATCH (contrib:GitContributor)-[:AUTHOR]->(commit:GitCommit)-[:BELONGS_TO]->(repo:GitRepository)\n",
    "                        WITH contrib, COUNT(DISTINCT repo) as repo_count\n",
    "                        RETURN contrib, repo_count ORDER BY repo_count DESC\n",
    "                    \"\"\"\n",
    "top10contributors = spark_read(SparkConnector.NEO4J, session, options=options)\n",
    "end_time = time.time()\n",
    "print(f\"Scenario 1: {end_time - start_time} sec\")\n",
    "display(top10contributors.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded from neo4j\n",
      "Scenario 2: 0.3414914608001709 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(repo_name='tensorflow/tensorflow', lang='C++', percOfBytes=0.63),\n",
       " Row(repo_name='electron/electron', lang='C++', percOfBytes=0.58)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scenario 2:\n",
    "\n",
    "start_time = time.time()\n",
    "LANGUAGE = \"C++\"\n",
    "PERCENTAGE = 0.5\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "options[\"query\"] = f\"\"\"\n",
    "                    MATCH (r:GitRepository)-[w:WRITTED_IN]->(l:GitLanguage)\n",
    "                    WITH r, SUM(w.bytes) AS totalBytesForRepo, collect({{language_name:l.name,bytes: w.bytes}}) AS bytesForLanguages\n",
    "                    UNWIND bytesForLanguages AS bytesForLanguage\n",
    "                    WITH r.name AS repo_name, bytesForLanguage.language_name AS lang, round((bytesForLanguage.bytes*1.0/totalBytesForRepo),2) AS percOfBytes\n",
    "                        WHERE lang = \"{LANGUAGE}\" AND percOfBytes > {PERCENTAGE}\n",
    "                    RETURN repo_name, lang, percOfBytes \n",
    "                  \"\"\"\n",
    "bytesPercentageInRepos = spark_read(SparkConnector.NEO4J, session, options=options)\n",
    "end_time = time.time()\n",
    "print(f\"Scenario 2: {end_time - start_time} sec\")\n",
    "display(bytesPercentageInRepos.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded from neo4j\n",
      "Scenario 3: 0.6592416763305664 sec\n",
      "+----------+\n",
      "|mergeCount|\n",
      "+----------+\n",
      "|     12127|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scenario 3:\n",
    "start_time = time.time()\n",
    "REPO_NAME = \"tensorflow/tensorflow\"\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "options[\"query\"] =  f\"\"\"\n",
    "                        MATCH (repository:GitRepository {{name: \"{REPO_NAME}\"}})<-[:BELONGS_TO]-(commit:GitCommit), \n",
    "                            r = (commit)-[:PARENT]->()\n",
    "                        WITH commit, collect(r) AS parents\n",
    "                        WHERE size(parents) > 1\n",
    "                        RETURN count(commit) AS mergeCount\n",
    "                    \"\"\"\n",
    "bytesPercentageInRepos = spark_read(SparkConnector.NEO4J, session, options=options)\n",
    "end_time = time.time()\n",
    "print(f\"Scenario 3: {end_time - start_time} sec\")\n",
    "bytesPercentageInRepos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Put query text in the neo4j GUI",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85/1163168496.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0mPROJ_NAME\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"contribRepoAndCommits\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Put query text in the neo4j GUI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Put query text in the neo4j GUI"
     ]
    }
   ],
   "source": [
    "# Scenario 4 - project graph contributors, commits and repos:\n",
    "query = \"\"\"     \n",
    "        CALL gds.graph.project.cypher(\n",
    "              'contribRepoAndCommits',\n",
    "              'MATCH (n) WHERE n:GitContributor OR n:GitCommit OR n:GitRepository RETURN ID(n) AS id',\n",
    "              'MATCH (n)-[r]->(m) WHERE r:PARENT OR r:BELONGS_TO OR r:COMMITTED OR r:AUTHOR RETURN ID(n) AS source, ID(m) AS target'\n",
    "        )\n",
    "        \"\"\"\n",
    "PROJ_NAME=\"contribRepoAndCommits\"\n",
    "raise Exception(\"Put query text in the neo4j GUI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded from neo4j\n"
     ]
    }
   ],
   "source": [
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "options[\"query\"] =  f\"\"\"\n",
    "                        MATCH (n)-[r]->(m) WHERE r:PARENT OR r:BELONGS_TO OR r:COMMITTED OR r:AUTHOR RETURN ID(n) AS source, ID(m) AS target \n",
    "                    \"\"\"\n",
    "louvain = spark_read(SparkConnector.NEO4J, session, options=options)\n",
    "louvain.write.option(\"header\", True).mode(\"overwrite\").csv(\"hdfs://namenode:9000//data-team/edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded from neo4j\n",
      "Scenario 4: 7.501660585403442 sec\n"
     ]
    }
   ],
   "source": [
    "# Scenario 4:\n",
    "start_time = time.time()\n",
    "PROJ_NAME = \"contribRepoAndCommits\"\n",
    "\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "options[\"query\"] =  f\"\"\"\n",
    "                        CALL gds.labelPropagation.stream('{PROJ_NAME}')\n",
    "                        YIELD nodeId, communityId\n",
    "                        RETURN nodeId as ID, communityId \n",
    "                    \"\"\"\n",
    "louvain = spark_read(SparkConnector.NEO4J, session, options=options)\n",
    "end_time = time.time()\n",
    "print(f\"Scenario 4: {end_time - start_time} sec\")\n",
    "louvain.write.option(\"header\", True).mode(\"overwrite\").csv(\"hdfs://namenode:9000//data-team/louvain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded from neo4j\n",
      "Scenario 5: 2.8513994216918945 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "options = get_default_options(SparkConnector.NEO4J)\n",
    "options[\"query\"] = f\"\"\"\n",
    "                        CALL gds.pageRank.stream('contribRepoAndCommits')\n",
    "                        YIELD nodeId, score\n",
    "                        RETURN nodeId, score\n",
    "                        ORDER BY score DESC\n",
    "                    \"\"\"\n",
    "louvain = spark_read(SparkConnector.NEO4J, session, options=options)\n",
    "end_time = time.time()\n",
    "print(f\"Scenario 5: {end_time - start_time} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sparkContext.stop()\n",
    "session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
